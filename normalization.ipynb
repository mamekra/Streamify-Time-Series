{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae2888a",
   "metadata": {},
   "source": [
    "## Step 0: Dataset Preparation\n",
    "\n",
    "In this notebook, we prepare the input datasets for anomaly detection in streaming settings. We use three domains from the TSB-UAD benchmark:\n",
    "\n",
    "- **Daphnet** (Parkinson's acceleration data)\n",
    "- **Genesis** (Synthetic mechanical data)\n",
    "- **NASA-MSL** (Mars spacecraft telemetry)\n",
    "\n",
    "We generate three Normality levels:\n",
    "\n",
    "- **Normality 1**: One domain (no shift)\n",
    "- **Normality 2**: Two domains concatenated (1 shift)\n",
    "- **Normality 3**: Three domains concatenated (2 shifts)\n",
    "\n",
    "Each time series is normalized individually before concatenation. We save the generated datasets as `.npy` files along with their distribution shift boundaries and visualizations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0edb49",
   "metadata": {},
   "source": [
    "### Import Libraries and Define Paths\n",
    "\n",
    "We begin by importing the required libraries and defining the folder structure. Make sure the folders `original_datasets/` and `generated_datasets/` exist and contain the expected data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d83c51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Base paths\n",
    "RAW_DATA_PATH = \"original_datasets\"\n",
    "OUTPUT_PATH = \"generated_datasets\"\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39db3ec",
   "metadata": {},
   "source": [
    "### Define Helper Functions\n",
    "\n",
    "We define utility functions to:\n",
    "- Read `.out` files\n",
    "- Normalize each time series with Z-score\n",
    "- Load all series from a domain folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69a74e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_out_file(filepath):\n",
    "    \"\"\"Reads a .out time series file and returns a NumPy array of floats.\"\"\"\n",
    "    data = []\n",
    "    labels = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                parts = line.strip().split(',')\n",
    "                value = float(parts[0])\n",
    "                label = int(parts[1]) if len(parts) > 1 else None\n",
    "                data.append(value)\n",
    "                labels.append(label)\n",
    "            except Exception:\n",
    "                continue\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "def normalize(ts):\n",
    "    \"\"\"Z-score normalization\"\"\"\n",
    "    return (ts - np.mean(ts)) / (np.std(ts) + 1e-8)\n",
    "\n",
    "def load_domain_timeseries(domain_folder):\n",
    "    \"\"\"Loads all .out files from a domain folder\"\"\"\n",
    "    full_path = os.path.join(RAW_DATA_PATH, domain_folder)\n",
    "    series = []\n",
    "    series_labels = []\n",
    "    for filename in os.listdir(full_path):\n",
    "        if filename.endswith(\".out\"):\n",
    "            ts, labels = read_out_file(os.path.join(full_path, filename))\n",
    "            if len(ts) > 0:\n",
    "                series.append(ts)\n",
    "                series_labels.append(labels)\n",
    "    return series, series_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab1cd15",
   "metadata": {},
   "source": [
    "### Load and Normalize Time Series\n",
    "\n",
    "Here, we load all available time series from each of the selected domains and apply Z-score normalization individually. This ensures that magnitude differences between domains don't distort anomaly scoring later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff747f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 40 time series from Daphnet.\n",
      "Loaded 6 time series from Genesis.\n",
      "Loaded 54 time series from NASA-MSL.\n"
     ]
    }
   ],
   "source": [
    "# Load datasets from each domain\n",
    "domains = [\"Daphnet\", \"Genesis\", \"NASA-MSL\"]\n",
    "all_series = {}\n",
    "\n",
    "for domain in domains:    \n",
    "    raw_series, raw_series_labels = load_domain_timeseries(domain)\n",
    "    norm_series = [normalize(ts) for ts in raw_series]\n",
    "    all_series[domain] = {\n",
    "        \"series\": norm_series,\n",
    "        \"labels\": raw_series_labels\n",
    "    }\n",
    "    print(f\"Loaded {len(norm_series)} time series from {domain}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4e8133",
   "metadata": {},
   "source": [
    "### Function to Save and Visualize Datasets\n",
    "\n",
    "This function:\n",
    "- Concatenates the selected time series\n",
    "- Tracks where domain boundaries (distribution shifts) occur\n",
    "- Saves the dataset as `.npy` and `.png`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f78a278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(name, series_list, labels_list, domains):\n",
    "    data = np.concatenate(series_list)\n",
    "    labels = np.concatenate(labels_list)\n",
    "    boundaries = []\n",
    "    offset = 0\n",
    "    for series in series_list:  # Exclude the last series — no boundary after it\n",
    "        offset += len(series)\n",
    "        boundaries.append(offset)\n",
    "\n",
    "    # Save data\n",
    "    np.save(os.path.join(OUTPUT_PATH, f\"{name}.npy\"), data)\n",
    "    np.save(os.path.join(OUTPUT_PATH, f\"{name}_boundaries.npy\"), np.array(boundaries))\n",
    "    np.save(os.path.join(OUTPUT_PATH, f\"{name}_labels.npy\"), np.array(labels))\n",
    "    print(f\"Saved {name} with shape {data.shape} and shift boundaries {boundaries}\")\n",
    "\n",
    "    # --- Plotting ---\n",
    "    plt.figure(figsize=(14, 4))\n",
    "    plt.style.use(\"seaborn-v0_8-muted\")\n",
    "\n",
    "    # Draw labeled segments\n",
    "    start_idx = 0\n",
    "    for i in range(1, len(data)):\n",
    "        if labels[i] != labels[i - 1]:\n",
    "            color = '#2c7bb6' if labels[i - 1] == 0 else '#d7191c'\n",
    "            plt.plot(range(start_idx, i), data[start_idx:i], color=color, linewidth=1.5)\n",
    "            start_idx = i\n",
    "\n",
    "    # Draw last segment\n",
    "    color = '#2c7bb6' if labels[-1] == 0 else '#d7191c'\n",
    "    plt.plot(range(start_idx, len(data)), data[start_idx:], color=color, linewidth=1.5)\n",
    "\n",
    "    # Draw domain boundaries\n",
    "    for b in boundaries:\n",
    "        plt.axvline(x=b, color='gray', linestyle='--', linewidth=1)\n",
    "\n",
    "    # Decorations\n",
    "    plt.title(f\"{name.replace('_', ' ').title()}  |  Domains: {' → '.join(domains)}\", fontsize=14, pad=10)\n",
    "    plt.xlabel(\"Time\", fontsize=12)\n",
    "    plt.ylabel(\"Value\", fontsize=12)\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save figure\n",
    "    plt.savefig(os.path.join(OUTPUT_PATH, f\"{name}.png\"), dpi=150)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b2bcf7",
   "metadata": {},
   "source": [
    "### Generate Normality 1, 2, and 3 Datasets\n",
    "\n",
    "We randomly pick one normalized time series from each domain and combine them according to the rules below:\n",
    "\n",
    "- **Normality 1**: Single time series from one domain\n",
    "- **Normality 2**: Two time series from two domains, concatenated\n",
    "- **Normality 3**: Three time series from three domains, concatenated\n",
    "\n",
    "Each result is saved along with a boundary marker file and a plot showing the transitions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86c79499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d3e676a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_samples(max_samples, all_series):\n",
    "    selected_indices = {}\n",
    "\n",
    "    for domain in domains:\n",
    "        available = len(all_series[domain][\"series\"])\n",
    "        num_samples = random.randint(1, min(max_samples, available))\n",
    "\n",
    "        # Randomly sample without replacement\n",
    "        indices = random.sample(range(available), num_samples)\n",
    "        selected_indices[domain] = indices\n",
    "\n",
    "    return selected_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2df18230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected indices per domain: {'Daphnet': [4, 27, 35, 29, 21, 16, 32, 24, 25, 19, 1, 31, 13, 37, 0, 3, 28, 8, 15, 17, 23, 10, 38], 'Genesis': [1, 4], 'NASA-MSL': [22, 28, 15, 2, 35, 23, 45, 44, 53, 38, 21, 49, 36, 12, 51, 50, 8, 43, 6, 48, 24, 32, 16, 3, 20, 27, 7, 47, 10, 42, 39, 30, 13]}\n"
     ]
    }
   ],
   "source": [
    "selected_indices = select_random_samples(55, all_series)\n",
    "print(\"Selected indices per domain:\", selected_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35a9cd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved normality_1_daphnet with shape (445440,) and shift boundaries [25600, 35200, 44800, 54400, 71040, 87680, 97280, 112000, 121600, 138240, 167040, 176640, 212480, 222080, 250880, 276480, 286080, 341120, 357760, 374400, 400000, 435840, 445440]\n",
      "Saved normality_1_genesis with shape (32440,) and shift boundaries [16220, 32440]\n",
      "Saved normality_1_nasa-msl with shape (80427,) and shift boundaries [2127, 4176, 6687, 8738, 12707, 14744, 15889, 18319, 18758, 21614, 23822, 26094, 32194, 36116, 36864, 38383, 40574, 41719, 43877, 46095, 48133, 54233, 56720, 57484, 59761, 61793, 63867, 66139, 69561, 71991, 75673, 77829, 80427]\n",
      "Saved normality_2_1_daphnet_genesis with shape (477880,) and shift boundaries [9600, 35200, 51420, 80220, 89820, 115420, 132060, 141660, 151260, 167900, 196700, 206300, 242140, 251740, 268380, 293980, 303580, 319800, 329400, 384440, 399160, 415800, 451640, 461240, 477880]\n",
      "Saved normality_2_2_daphnet_nasa-msl with shape (525867,) and shift boundaries [2511, 4941, 7218, 43058, 59698, 88498, 91920, 95842, 97893, 114533, 116582, 122682, 126364, 128520, 143240, 152840, 155438, 191278, 193765, 203365, 220005, 222163, 231763, 234035, 243635, 244383, 245528, 247602, 248041, 250259, 251023, 260623, 270223, 295823, 305423, 331023, 333061, 335269, 344869, 346388, 355988, 358115, 362084, 364514, 366786, 368977, 371833, 426873, 443513, 460153, 462185, 463330, 469430, 498230, 523830, 525867]\n",
      "Saved normality_2_3_genesis_nasa-msl with shape (112867,) and shift boundaries [2487, 4705, 6779, 9051, 15151, 19120, 21976, 25898, 28089, 30519, 31283, 37383, 38528, 39276, 41308, 44990, 47146, 49195, 51793, 55215, 57252, 58397, 74617, 76775, 77214, 78733, 81244, 83521, 85572, 87699, 89737, 105957, 108229, 110659, 112867]\n",
      "Saved normality_3_1_daphnet_genesis_nasa-msl with shape (558307,) and shift boundaries [2032, 2780, 12380, 14978, 31618, 37718, 39769, 65369, 66888, 68962, 104802, 114402, 116558, 118830, 128430, 138030, 154250, 209290, 211328, 236928, 238965, 242647, 245503, 271103, 299903, 316543, 345343, 347470, 357070, 363170, 379390, 380535, 382693, 385180, 401820, 404038, 404477, 406754, 409265, 418865, 421056, 425025, 427455, 429885, 446525, 456125, 460047, 461192, 461956, 464228, 480868, 490468, 493890, 495939, 510659, 520259, 522467, 558307]\n",
      "Saved normality_3_2_genesis_nasa-msl_daphnet with shape (558307,) and shift boundaries [25600, 51200, 67840, 69998, 79598, 81725, 117565, 120421, 130021, 132177, 134385, 135530, 137567, 192607, 194681, 197111, 213331, 217253, 219444, 221955, 238175, 263775, 264214, 266701, 276301, 278573, 295213, 301313, 304735, 307165, 316765, 317513, 319032, 347832, 357432, 359470, 361519, 376239, 378271, 394911, 411551, 421151, 427251, 429849, 432067, 432831, 468671, 472353, 476322, 478373, 495013, 504613, 506885, 516485, 545285, 547562, 548707, 558307]\n",
      "Saved normality_3_3_nasa-msl_daphnet_genesis with shape (558307,) and shift boundaries [3682, 9782, 64822, 67678, 83898, 85949, 88436, 105076, 106221, 106660, 121380, 123454, 125662, 129084, 154684, 164284, 166442, 167206, 192806, 193951, 210591, 227231, 229263, 231390, 237490, 239708, 241745, 242493, 244923, 270523, 274445, 290665, 294634, 304234, 313834, 316345, 352185, 354457, 364057, 373657, 376087, 385687, 395287, 411927, 440727, 443004, 471804, 488444, 490493, 500093, 502131, 504322, 540162, 549762, 552360, 553879, 556151, 558307]\n"
     ]
    }
   ],
   "source": [
    "# Normality 1\n",
    "for domain in domains:\n",
    "    # Get the series and labels\n",
    "    series_list = all_series[domain][\"series\"]\n",
    "    labels_list = all_series[domain][\"labels\"]\n",
    "    # Get random domain indexes\n",
    "    indices = selected_indices[domain]\n",
    "    # Extract random sample\n",
    "    random_series = [series_list[idx] for idx in indices]\n",
    "    random_labels = [labels_list[idx] for idx in indices]\n",
    "    save_dataset(f\"normality_1_{domain.lower()}\", random_series, random_labels, [domain])\n",
    "\n",
    "# Normality 2\n",
    "pairs = [(\"Daphnet\", \"Genesis\"), (\"Daphnet\", \"NASA-MSL\"), (\"Genesis\", \"NASA-MSL\")]\n",
    "for i, (dom1, dom2) in enumerate(pairs, 1):\n",
    "    # Get random domain indexes\n",
    "    indices1 = selected_indices[dom1]\n",
    "    indices2 = selected_indices[dom2]\n",
    "\n",
    "    # Collect (series, label, domain) tuples\n",
    "    combined = [\n",
    "        (all_series[dom1][\"series\"][idx], all_series[dom1][\"labels\"][idx], dom1)\n",
    "        for idx in indices1\n",
    "    ] + [\n",
    "        (all_series[dom2][\"series\"][idx], all_series[dom2][\"labels\"][idx], dom2)\n",
    "        for idx in indices2\n",
    "    ]\n",
    "\n",
    "    # Shuffle the combined data\n",
    "    random.shuffle(combined)\n",
    "\n",
    "    # Unpack shuffled components\n",
    "    shuffled_series, shuffled_labels, shuffled_domains = zip(*combined)\n",
    "\n",
    "    save_dataset(\n",
    "        f\"normality_2_{i}_{dom1.lower()}_{dom2.lower()}\",\n",
    "        list(shuffled_series),\n",
    "        list(shuffled_labels),\n",
    "        list(shuffled_domains)\n",
    "    )\n",
    "\n",
    "# Normality 3\n",
    "perms = [\n",
    "    (\"Daphnet\", \"Genesis\", \"NASA-MSL\"),\n",
    "    (\"Genesis\", \"NASA-MSL\", \"Daphnet\"),\n",
    "    (\"NASA-MSL\", \"Daphnet\", \"Genesis\")\n",
    "]\n",
    "for i, (dom1, dom2, dom3) in enumerate(perms, 1):\n",
    "    indices1 = selected_indices[dom1]\n",
    "    indices2 = selected_indices[dom2]\n",
    "    indices3 = selected_indices[dom3]\n",
    "    # Get selected indices\n",
    "    indices1 = selected_indices[dom1]\n",
    "    indices2 = selected_indices[dom2]\n",
    "    indices3 = selected_indices[dom3]\n",
    "\n",
    "    # Collect (series, label, domain) tuples\n",
    "    combined = [\n",
    "        (all_series[dom1][\"series\"][idx], all_series[dom1][\"labels\"][idx], dom1)\n",
    "        for idx in indices1\n",
    "    ] + [\n",
    "        (all_series[dom2][\"series\"][idx], all_series[dom2][\"labels\"][idx], dom2)\n",
    "        for idx in indices2\n",
    "    ] + [\n",
    "        (all_series[dom3][\"series\"][idx], all_series[dom3][\"labels\"][idx], dom3)\n",
    "        for idx in indices3\n",
    "    ]\n",
    "\n",
    "    # Shuffle the combined data\n",
    "    random.shuffle(combined)\n",
    "\n",
    "    # Unpack shuffled components\n",
    "    shuffled_series, shuffled_labels, shuffled_domains = zip(*combined)\n",
    "\n",
    "    save_dataset(\n",
    "        f\"normality_3_{i}_{dom1.lower()}_{dom2.lower()}_{dom3.lower()}\",\n",
    "        list(shuffled_series),\n",
    "        list(shuffled_labels),\n",
    "        list(shuffled_domains)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nikosVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
