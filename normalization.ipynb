{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae2888a",
   "metadata": {},
   "source": [
    "## Step 0: Dataset Preparation\n",
    "\n",
    "In this notebook, we prepare the input datasets for anomaly detection in streaming settings. We use three domains from the TSB-UAD benchmark:\n",
    "\n",
    "- **Daphnet** (Parkinson's acceleration data)\n",
    "- **Genesis** (Synthetic mechanical data)\n",
    "- **NASA-MSL** (Mars spacecraft telemetry)\n",
    "\n",
    "We generate three Normality levels:\n",
    "\n",
    "- **Normality 1**: One domain (no shift)\n",
    "- **Normality 2**: Two domains concatenated (1 shift)\n",
    "- **Normality 3**: Three domains concatenated (2 shifts)\n",
    "\n",
    "Each time series is normalized individually before concatenation. We save the generated datasets as `.npy` files along with their distribution shift boundaries and visualizations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0edb49",
   "metadata": {},
   "source": [
    "### Import Libraries and Define Paths\n",
    "\n",
    "We begin by importing the required libraries and defining the folder structure. Make sure the folders `original_datasets/` and `generated_datasets/` exist and contain the expected data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d83c51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Base paths\n",
    "RAW_DATA_PATH = \"original_datasets\"\n",
    "OUTPUT_PATH = \"generated_datasets\"\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39db3ec",
   "metadata": {},
   "source": [
    "### Define Helper Functions\n",
    "\n",
    "We define utility functions to:\n",
    "- Read `.out` files\n",
    "- Normalize each time series with Z-score\n",
    "- Load all series from a domain folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69a74e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_out_file(filepath):\n",
    "    \"\"\"Reads a .out time series file and returns a NumPy array of floats.\"\"\"\n",
    "    data = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                value = float(line.strip().split(',')[0])\n",
    "                data.append(value)\n",
    "            except Exception:\n",
    "                continue\n",
    "    return np.array(data)\n",
    "\n",
    "def normalize(ts):\n",
    "    \"\"\"Z-score normalization\"\"\"\n",
    "    return (ts - np.mean(ts)) / (np.std(ts) + 1e-8)\n",
    "\n",
    "def load_domain_timeseries(domain_folder):\n",
    "    \"\"\"Loads all .out files from a domain folder\"\"\"\n",
    "    full_path = os.path.join(RAW_DATA_PATH, domain_folder)\n",
    "    series = []\n",
    "    for filename in os.listdir(full_path):\n",
    "        if filename.endswith(\".out\"):\n",
    "            ts = read_out_file(os.path.join(full_path, filename))\n",
    "            if len(ts) > 0:\n",
    "                series.append(ts)\n",
    "    return series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab1cd15",
   "metadata": {},
   "source": [
    "### Load and Normalize Time Series\n",
    "\n",
    "Here, we load all available time series from each of the selected domains and apply Z-score normalization individually. This ensures that magnitude differences between domains don't distort anomaly scoring later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff747f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 45 time series.\n",
      "Loaded 6 time series.\n",
      "Loaded 54 time series.\n"
     ]
    }
   ],
   "source": [
    "# Load datasets from each domain\n",
    "domains = [\"Daphnet\", \"Genesis\", \"NASA-MSL\"]\n",
    "all_series = {}\n",
    "\n",
    "for domain in domains:    \n",
    "    raw_series = load_domain_timeseries(domain)\n",
    "    norm_series = [normalize(ts) for ts in raw_series]\n",
    "    all_series[domain] = norm_series\n",
    "    print(f\"Loaded {len(norm_series)} time series.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4e8133",
   "metadata": {},
   "source": [
    "### Function to Save and Visualize Datasets\n",
    "\n",
    "This function:\n",
    "- Concatenates the selected time series\n",
    "- Tracks where domain boundaries (distribution shifts) occur\n",
    "- Saves the dataset as `.npy` and `.png`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f78a278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(name, series_list, domains):\n",
    "    data = np.concatenate(series_list)\n",
    "    boundaries = [len(series_list[0])]\n",
    "    if len(series_list) > 2:\n",
    "        boundaries.append(boundaries[0] + len(series_list[1]))\n",
    "    np.save(os.path.join(OUTPUT_PATH, f\"{name}.npy\"), data)\n",
    "    np.save(os.path.join(OUTPUT_PATH, f\"{name}_boundaries.npy\"), np.array(boundaries))\n",
    "    print(f\"Saved {name} with shape {data.shape} and shift boundaries {boundaries}\")\n",
    "\n",
    "    # Optional: plot\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(data, label='Time Series')\n",
    "    for b in boundaries:\n",
    "        plt.axvline(x=b, color='red', linestyle='--', label='Distribution shift')\n",
    "    plt.title(f\"{name} - {' â†’ '.join(domains)}\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_PATH, f\"{name}.png\"))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b2bcf7",
   "metadata": {},
   "source": [
    "### Generate Normality 1, 2, and 3 Datasets\n",
    "\n",
    "We randomly pick one normalized time series from each domain and combine them according to the rules below:\n",
    "\n",
    "- **Normality 1**: Single time series from one domain\n",
    "- **Normality 2**: Two time series from two domains, concatenated\n",
    "- **Normality 3**: Three time series from three domains, concatenated\n",
    "\n",
    "Each result is saved along with a boundary marker file and a plot showing the transitions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35a9cd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved normality_1_daphnet with shape (35840,) and shift boundaries [35840]\n",
      "Saved normality_1_genesis with shape (16220,) and shift boundaries [16220]\n",
      "Saved normality_1_nasa-msl with shape (3969,) and shift boundaries [3969]\n",
      "Saved normality_2_1_daphnet_genesis with shape (25820,) and shift boundaries [9600]\n",
      "Saved normality_2_2_daphnet_nasa-msl with shape (36279,) and shift boundaries [35840]\n",
      "Saved normality_2_3_genesis_nasa-msl with shape (18492,) and shift boundaries [16220]\n",
      "Saved normality_3_1_daphnet_genesis_nasa-msl with shape (54363,) and shift boundaries [35840, 52060]\n",
      "Saved normality_3_2_genesis_nasa-msl_daphnet with shape (53887,) and shift boundaries [16220, 18047]\n",
      "Saved normality_3_3_nasa-msl_daphnet_genesis with shape (27871,) and shift boundaries [2051, 11651]\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "# Normality 1\n",
    "for domain in domains:\n",
    "    ts = random.choice(all_series[domain])\n",
    "    save_dataset(f\"normality_1_{domain.lower()}\", [ts], [domain])\n",
    "\n",
    "# Normality 2\n",
    "pairs = [(\"Daphnet\", \"Genesis\"), (\"Daphnet\", \"NASA-MSL\"), (\"Genesis\", \"NASA-MSL\")]\n",
    "for i, (dom1, dom2) in enumerate(pairs, 1):\n",
    "    ts1 = random.choice(all_series[dom1])\n",
    "    ts2 = random.choice(all_series[dom2])\n",
    "    save_dataset(f\"normality_2_{i}_{dom1.lower()}_{dom2.lower()}\", [ts1, ts2], [dom1, dom2])\n",
    "\n",
    "# Normality 3\n",
    "perms = [\n",
    "    (\"Daphnet\", \"Genesis\", \"NASA-MSL\"),\n",
    "    (\"Genesis\", \"NASA-MSL\", \"Daphnet\"),\n",
    "    (\"NASA-MSL\", \"Daphnet\", \"Genesis\")\n",
    "]\n",
    "for i, (dom1, dom2, dom3) in enumerate(perms, 1):\n",
    "    ts1 = random.choice(all_series[dom1])\n",
    "    ts2 = random.choice(all_series[dom2])\n",
    "    ts3 = random.choice(all_series[dom3])\n",
    "    save_dataset(f\"normality_3_{i}_{dom1.lower()}_{dom2.lower()}_{dom3.lower()}\", [ts1, ts2, ts3], [dom1, dom2, dom3])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
