{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae2888a",
   "metadata": {},
   "source": [
    "## Step 0: Dataset Preparation\n",
    "\n",
    "In this notebook, we prepare the input datasets for anomaly detection in streaming settings. We use three domains from the TSB-UAD benchmark:\n",
    "\n",
    "- **Daphnet** (Parkinson's acceleration data)\n",
    "- **Genesis** (Synthetic mechanical data)\n",
    "- **NASA-MSL** (Mars spacecraft telemetry)\n",
    "\n",
    "We generate three Normality levels:\n",
    "\n",
    "- **Normality 1**: One domain (no shift)\n",
    "- **Normality 2**: Two domains concatenated (1 shift)\n",
    "- **Normality 3**: Three domains concatenated (2 shifts)\n",
    "\n",
    "Each time series is normalized individually before concatenation. We save the generated datasets as `.npy` files along with their distribution shift boundaries and visualizations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0edb49",
   "metadata": {},
   "source": [
    "### Import Libraries and Define Paths\n",
    "\n",
    "We begin by importing the required libraries and defining the folder structure. Make sure the folders `original_datasets/` and `generated_datasets/` exist and contain the expected data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d83c51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Base paths\n",
    "RAW_DATA_PATH = \"original_datasets\"\n",
    "OUTPUT_PATH = \"generated_datasets\"\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39db3ec",
   "metadata": {},
   "source": [
    "### Define Helper Functions\n",
    "\n",
    "We define utility functions to:\n",
    "- Read `.out` files\n",
    "- Normalize each time series with Z-score\n",
    "- Load all series from a domain folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69a74e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_out_file(filepath):\n",
    "    \"\"\"Reads a .out time series file and returns a NumPy array of floats.\"\"\"\n",
    "    data = []\n",
    "    labels = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                parts = line.strip().split(',')\n",
    "                value = float(parts[0])\n",
    "                label = int(parts[1]) if len(parts) > 1 else None\n",
    "                data.append(value)\n",
    "                labels.append(label)\n",
    "            except Exception:\n",
    "                continue\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "def normalize(ts):\n",
    "    \"\"\"Z-score normalization\"\"\"\n",
    "    return (ts - np.mean(ts)) / (np.std(ts) + 1e-8)\n",
    "\n",
    "def load_domain_timeseries(domain_folder):\n",
    "    \"\"\"Loads all .out files from a domain folder\"\"\"\n",
    "    full_path = os.path.join(RAW_DATA_PATH, domain_folder)\n",
    "    series = []\n",
    "    series_labels = []\n",
    "    for filename in os.listdir(full_path):\n",
    "        if filename.endswith(\".out\"):\n",
    "            ts, labels = read_out_file(os.path.join(full_path, filename))\n",
    "            if len(ts) > 0:\n",
    "                series.append(ts)\n",
    "                series_labels.append(labels)\n",
    "    return series, series_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab1cd15",
   "metadata": {},
   "source": [
    "### Load and Normalize Time Series\n",
    "\n",
    "Here, we load all available time series from each of the selected domains and apply Z-score normalization individually. This ensures that magnitude differences between domains don't distort anomaly scoring later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ff747f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 40 time series from Daphnet.\n",
      "Loaded 6 time series from Genesis.\n",
      "Loaded 54 time series from NASA-MSL.\n"
     ]
    }
   ],
   "source": [
    "# Load datasets from each domain\n",
    "domains = [\"Daphnet\", \"Genesis\", \"NASA-MSL\"]\n",
    "all_series = {}\n",
    "\n",
    "for domain in domains:    \n",
    "    raw_series, raw_series_labels = load_domain_timeseries(domain)\n",
    "    norm_series = [normalize(ts) for ts in raw_series]\n",
    "    all_series[domain] = {\n",
    "        \"series\": norm_series,\n",
    "        \"labels\": raw_series_labels\n",
    "    }\n",
    "    print(f\"Loaded {len(norm_series)} time series from {domain}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4e8133",
   "metadata": {},
   "source": [
    "### Function to Save and Visualize Datasets\n",
    "\n",
    "This function:\n",
    "- Concatenates the selected time series\n",
    "- Tracks where domain boundaries (distribution shifts) occur\n",
    "- Saves the dataset as `.npy` and `.png`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8f78a278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(name, series_list, labels_list, domains):\n",
    "    data = np.concatenate(series_list)\n",
    "    labels = np.concatenate(labels_list)\n",
    "    boundaries = []\n",
    "    offset = 0\n",
    "    for series in series_list:  # Exclude the last series — no boundary after it\n",
    "        offset += len(series)\n",
    "        boundaries.append(offset)\n",
    "\n",
    "    # Save data\n",
    "    np.save(os.path.join(OUTPUT_PATH, f\"{name}.npy\"), data)\n",
    "    np.save(os.path.join(OUTPUT_PATH, f\"{name}_boundaries.npy\"), np.array(boundaries))\n",
    "    np.save(os.path.join(OUTPUT_PATH, f\"{name}_labels.npy\"), np.array(labels))\n",
    "    print(f\"Saved {name} with shape {data.shape} and shift boundaries {boundaries}\")\n",
    "\n",
    "    # --- Plotting ---\n",
    "    plt.figure(figsize=(14, 4))\n",
    "    plt.style.use(\"seaborn-v0_8-muted\")\n",
    "\n",
    "    # Draw labeled segments\n",
    "    start_idx = 0\n",
    "    for i in range(1, len(data)):\n",
    "        if labels[i] != labels[i - 1]:\n",
    "            color = '#2c7bb6' if labels[i - 1] == 0 else '#d7191c'\n",
    "            plt.plot(range(start_idx, i), data[start_idx:i], color=color, linewidth=1.5)\n",
    "            start_idx = i\n",
    "\n",
    "    # Draw last segment\n",
    "    color = '#2c7bb6' if labels[-1] == 0 else '#d7191c'\n",
    "    plt.plot(range(start_idx, len(data)), data[start_idx:], color=color, linewidth=1.5)\n",
    "\n",
    "    # Draw domain boundaries\n",
    "    for b in boundaries:\n",
    "        plt.axvline(x=b, color='gray', linestyle='--', linewidth=1)\n",
    "\n",
    "    # Decorations\n",
    "    plt.title(f\"{name.replace('_', ' ').title()}  |  Domains: {' → '.join(domains)}\", fontsize=14, pad=10)\n",
    "    plt.xlabel(\"Time\", fontsize=12)\n",
    "    plt.ylabel(\"Value\", fontsize=12)\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save figure\n",
    "    plt.savefig(os.path.join(OUTPUT_PATH, f\"{name}.png\"), dpi=150)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b2bcf7",
   "metadata": {},
   "source": [
    "### Generate Normality 1, 2, and 3 Datasets\n",
    "\n",
    "We randomly pick one normalized time series from each domain and combine them according to the rules below:\n",
    "\n",
    "- **Normality 1**: Single time series from one domain\n",
    "- **Normality 2**: Two time series from two domains, concatenated\n",
    "- **Normality 3**: Three time series from three domains, concatenated\n",
    "\n",
    "Each result is saved along with a boundary marker file and a plot showing the transitions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "86c79499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1d3e676a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_samples(max_samples, all_series):\n",
    "    selected_indices = {}\n",
    "\n",
    "    for domain in domains:\n",
    "        num_samples = random.randint(1, max_samples)\n",
    "        available = len(all_series[domain][\"series\"])\n",
    "\n",
    "        # Randomly sample without replacement\n",
    "        indices = random.sample(range(available), num_samples)\n",
    "        selected_indices[domain] = indices\n",
    "\n",
    "    return selected_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2df18230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected indices per domain: {'Daphnet': [4, 27, 35], 'Genesis': [4, 2, 5, 3], 'NASA-MSL': [25, 39, 2, 50]}\n"
     ]
    }
   ],
   "source": [
    "selected_indices = select_random_samples(5, all_series)\n",
    "print(\"Selected indices per domain:\", selected_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "35a9cd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved normality_1_daphnet with shape (44800,) and shift boundaries [25600, 35200, 44800]\n",
      "Saved normality_1_genesis with shape (64880,) and shift boundaries [16220, 32440, 48660, 64880]\n",
      "Saved normality_1_nasa-msl with shape (9328,) and shift boundaries [2051, 4127, 5646, 9328]\n",
      "Saved normality_2_1_daphnet_genesis with shape (109680,) and shift boundaries [9600, 25820, 42040, 58260, 74480, 100080, 109680]\n",
      "Saved normality_2_2_daphnet_nasa-msl with shape (54128,) and shift boundaries [25600, 35200, 38882, 48482, 50533, 52609, 54128]\n",
      "Saved normality_2_3_genesis_nasa-msl with shape (74208,) and shift boundaries [1519, 17739, 33959, 36010, 52230, 55912, 57988, 74208]\n",
      "Saved normality_3_1_daphnet_genesis_nasa-msl with shape (119008,) and shift boundaries [9600, 25820, 35420, 51640, 67860, 69911, 71987, 73506, 89726, 115326, 119008]\n",
      "Saved normality_3_2_genesis_nasa-msl_daphnet with shape (119008,) and shift boundaries [9600, 25820, 27896, 44116, 47798, 49317, 58917, 75137, 91357, 93408, 119008]\n",
      "Saved normality_3_3_nasa-msl_daphnet_genesis with shape (119008,) and shift boundaries [16220, 32440, 48660, 74260, 75779, 85379, 89061, 91137, 93188, 109408, 119008]\n"
     ]
    }
   ],
   "source": [
    "# Normality 1\n",
    "for domain in domains:\n",
    "    # Get the series and labels\n",
    "    series_list = all_series[domain][\"series\"]\n",
    "    labels_list = all_series[domain][\"labels\"]\n",
    "    # Get random domain indexes\n",
    "    indices = selected_indices[domain]\n",
    "    # Extract random sample\n",
    "    random_series = [series_list[idx] for idx in indices]\n",
    "    random_labels = [labels_list[idx] for idx in indices]\n",
    "    save_dataset(f\"normality_1_{domain.lower()}\", random_series, random_labels, [domain])\n",
    "\n",
    "# Normality 2\n",
    "pairs = [(\"Daphnet\", \"Genesis\"), (\"Daphnet\", \"NASA-MSL\"), (\"Genesis\", \"NASA-MSL\")]\n",
    "for i, (dom1, dom2) in enumerate(pairs, 1):\n",
    "    # Get random domain indexes\n",
    "    indices1 = selected_indices[dom1]\n",
    "    indices2 = selected_indices[dom2]\n",
    "\n",
    "    # Collect (series, label, domain) tuples\n",
    "    combined = [\n",
    "        (all_series[dom1][\"series\"][idx], all_series[dom1][\"labels\"][idx], dom1)\n",
    "        for idx in indices1\n",
    "    ] + [\n",
    "        (all_series[dom2][\"series\"][idx], all_series[dom2][\"labels\"][idx], dom2)\n",
    "        for idx in indices2\n",
    "    ]\n",
    "\n",
    "    # Shuffle the combined data\n",
    "    random.shuffle(combined)\n",
    "\n",
    "    # Unpack shuffled components\n",
    "    shuffled_series, shuffled_labels, shuffled_domains = zip(*combined)\n",
    "\n",
    "    save_dataset(\n",
    "        f\"normality_2_{i}_{dom1.lower()}_{dom2.lower()}\",\n",
    "        list(shuffled_series),\n",
    "        list(shuffled_labels),\n",
    "        list(shuffled_domains)\n",
    "    )\n",
    "\n",
    "# Normality 3\n",
    "perms = [\n",
    "    (\"Daphnet\", \"Genesis\", \"NASA-MSL\"),\n",
    "    (\"Genesis\", \"NASA-MSL\", \"Daphnet\"),\n",
    "    (\"NASA-MSL\", \"Daphnet\", \"Genesis\")\n",
    "]\n",
    "for i, (dom1, dom2, dom3) in enumerate(perms, 1):\n",
    "    indices1 = selected_indices[dom1]\n",
    "    indices2 = selected_indices[dom2]\n",
    "    indices3 = selected_indices[dom3]\n",
    "    # Get selected indices\n",
    "    indices1 = selected_indices[dom1]\n",
    "    indices2 = selected_indices[dom2]\n",
    "    indices3 = selected_indices[dom3]\n",
    "\n",
    "    # Collect (series, label, domain) tuples\n",
    "    combined = [\n",
    "        (all_series[dom1][\"series\"][idx], all_series[dom1][\"labels\"][idx], dom1)\n",
    "        for idx in indices1\n",
    "    ] + [\n",
    "        (all_series[dom2][\"series\"][idx], all_series[dom2][\"labels\"][idx], dom2)\n",
    "        for idx in indices2\n",
    "    ] + [\n",
    "        (all_series[dom3][\"series\"][idx], all_series[dom3][\"labels\"][idx], dom3)\n",
    "        for idx in indices3\n",
    "    ]\n",
    "\n",
    "    # Shuffle the combined data\n",
    "    random.shuffle(combined)\n",
    "\n",
    "    # Unpack shuffled components\n",
    "    shuffled_series, shuffled_labels, shuffled_domains = zip(*combined)\n",
    "\n",
    "    save_dataset(\n",
    "        f\"normality_3_{i}_{dom1.lower()}_{dom2.lower()}_{dom3.lower()}\",\n",
    "        list(shuffled_series),\n",
    "        list(shuffled_labels),\n",
    "        list(shuffled_domains)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nikosVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
